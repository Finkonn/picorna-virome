{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the file with GenBank records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/kobuvirus.gb'\n",
    "genbank_records = SeqIO.parse(file_path, 'gb')\n",
    "genbank_records = list(genbank_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create empty lists for storing qualifier information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts = []\n",
    "collection_dates = []\n",
    "countries = []\n",
    "isolation_sources = []\n",
    "isolates = []\n",
    "strains = []\n",
    "serotypes = []\n",
    "record_ids = []\n",
    "references = []\n",
    "number_of_records = 0\n",
    "CDS_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 422\n",
      "Number of CDS: 363\n",
      "Hosts: ['Sus scrofa (domestic pig)', 'Sus scrofa', 'domestic pig', 'Coracias garrulus (European roller)', 'Mus musculus']\n",
      "Collection Dates: ['2007', '2018', '2013', 'Jul-2011', 'May-2022']\n",
      "Countries: ['Hungary', 'Germany', 'China', 'Hungary', 'USA: MN']\n",
      "Isolation Sources: ['feces', 'nasal swab', 'fecal sample', 'fecal sample', 'Unknown']\n",
      "Isolates: ['Unknown', 'Unknown', 'Unknown', 'Unknown', 'Murine kobuvirus MKV1/Mus_musculus/AJ32-MKV/2022/MN-USA']\n",
      "Strains: ['swine/S-1-HUN/2007/Hungary', 'FoPro-213.14/GER/2018', 'JS-01-CHN/2013/China', 'SZAL6-KoV/2011/HUN', 'Unknown']\n",
      "Serotypes: ['Porcine kobuvirus swine/S-1-HUN/2007/Hungary', 'Porcine kobuvirus', 'Porcine kobuvirus JS-01-CHN/2013/China', 'aichivirus A5', 'aichivirus A8']\n",
      "Record IDs: ['NC_011829', 'MZ334483', 'KP144318', 'KJ934637', 'PQ110018']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The function checks if the qualifier is a list and returns the appropriate value.\n",
    "If the qualifier is a list, its first element is returned.\n",
    "If the qualifier is not a list, it is returned as is.\n",
    "If the qualifier is not found by the key, the string 'Unknown' is returned. \n",
    "\"\"\"\n",
    "def parse_qualifier(qualifier, key):\n",
    "    value = qualifier.get(key, 'Unknown')\n",
    "    return value if not isinstance(value, list) else value[0]\n",
    "\n",
    "def merge_values(values):\n",
    "    for value in values:\n",
    "        if value != 'Unknown':\n",
    "            return value\n",
    "    return 'Unknown'\n",
    "\n",
    "def extract_data_from_record(record):\n",
    "    features = record.features\n",
    "    source_feature_list = [feature for feature in features if feature.type == 'source']\n",
    "\n",
    "    merged_values = {\n",
    "        'host': [],\n",
    "        'collection_date': [],\n",
    "        'geo_loc_name': [],\n",
    "        'isolation_source': [],\n",
    "        'isolate': [],\n",
    "        'strain': [],\n",
    "        'organism': []\n",
    "    }\n",
    "\n",
    "    for source_feature in source_feature_list:\n",
    "        qual_dict = source_feature.qualifiers\n",
    "\n",
    "        for key in merged_values.keys():\n",
    "            merged_values[key].append(parse_qualifier(qual_dict, key))\n",
    "\n",
    "    hosts.append(merge_values(merged_values['host']))\n",
    "    collection_dates.append(merge_values(merged_values['collection_date']))\n",
    "    countries.append(merge_values(merged_values['geo_loc_name']))\n",
    "    isolation_sources.append(merge_values(merged_values['isolation_source']))\n",
    "    isolates.append(merge_values(merged_values['isolate']))\n",
    "    strains.append(merge_values(merged_values['strain']))\n",
    "    serotypes.append(merge_values(merged_values['organism']))\n",
    "\n",
    "    for reference in record.annotations[\"references\"]:\n",
    "        references.append(reference.title)\n",
    "        break\n",
    " \n",
    "    record_ids.append(record.name)\n",
    "\n",
    "for record in genbank_records:\n",
    "    extract_data_from_record(record)\n",
    "    CDS_count += sum(1 for feature in record.features if feature.type == 'CDS')\n",
    "    number_of_records += 1\n",
    "\n",
    "print(\"Number of records:\", number_of_records)\n",
    "print(\"Number of CDS:\", CDS_count)\n",
    "print(\"Hosts:\", hosts[:5])\n",
    "print(\"Collection Dates:\", collection_dates[:5])\n",
    "print(\"Countries:\", countries[:5])\n",
    "print(\"Isolation Sources:\", isolation_sources[:5])\n",
    "print(\"Isolates:\", isolates[:5])\n",
    "print(\"Strains:\", strains[:5])\n",
    "print(\"Serotypes:\", serotypes[:5])\n",
    "print(\"Record IDs:\", record_ids[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading map.csv files\n",
    "def read_csv(file_name):\n",
    "    with open(file_name) as csvfile:\n",
    "        reader = csv.DictReader(csvfile,\n",
    "                                delimiter=\",\", \n",
    "                                fieldnames=[\"base\", \"new\"])\n",
    "        result = {}\n",
    "        \n",
    "        for row in reader:\n",
    "            base_value = row[\"base\"].strip()\n",
    "            new_value = row[\"new\"].strip().rstrip(';')\n",
    "            result[base_value] = new_value\n",
    "        csvfile.close()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function maps values from a list to values in a CSV file.\n",
    "def map_qualifiers(qualifier, csv_file):\n",
    "    data_dict = read_csv(csv_file)\n",
    "    feature_map_comp = [(re.compile(key), value) for key, value in data_dict.items()]\n",
    "    mapped_values = []\n",
    "    for name in qualifier:\n",
    "        for regex, new_name in feature_map_comp:\n",
    "            match = regex.search(name)\n",
    "            if match:\n",
    "                mapped_values.append(new_name)\n",
    "                break\n",
    "        else:\n",
    "            mapped_values.append(name)\n",
    "    return mapped_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading map.csv files\n",
    "def read_csv_kobu(file_name):\n",
    "    with open(file_name) as csvfile:\n",
    "        reader = csv.DictReader(csvfile,\n",
    "                                delimiter=\";\", \n",
    "                                fieldnames=[\"base\", \"new\"])\n",
    "        result = {}\n",
    "        \n",
    "        for row in reader:\n",
    "            base_value = row[\"base\"].strip()\n",
    "            new_value = row[\"new\"].strip()\n",
    "            result[base_value] = new_value\n",
    "        csvfile.close()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function maps values from a list to values in a CSV file.\n",
    "def map_qualifiers_kobu(qualifier, csv_file):\n",
    "    data_dict = read_csv_kobu(csv_file)\n",
    "    feature_map_comp = [(re.compile(key), value) for key, value in data_dict.items()]\n",
    "    mapped_values = []\n",
    "    for name in qualifier:\n",
    "        for regex, new_name in feature_map_comp:\n",
    "            match = regex.search(name)\n",
    "            if match:\n",
    "                mapped_values.append(new_name)\n",
    "                break\n",
    "        else:\n",
    "            mapped_values.append(name)\n",
    "    return mapped_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping hosts\n",
    "hosts_mapped = map_qualifiers(hosts, '../data/tables_and_maps/host_map.csv')\n",
    "\n",
    "# Mapping countries\n",
    "countries_mapped = map_qualifiers(countries, '../data/tables_and_maps/country_map.csv')\n",
    "\n",
    "#Mapping types\n",
    "serotypes_mapped = map_qualifiers_kobu(serotypes, '../data/tables_and_maps/kobu_map.csv')\n",
    "\n",
    "# Converting all dates to years\n",
    "collection_years = ['Unknown' if date == 'Unknown' else (date[-4:] if date[-4:].isdigit() else date[:4]) for date in collection_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function prints unique values and their count in the list\n",
    "def print_sorted_counts(items):\n",
    "    count_dict = {}\n",
    "    for item in items:    \n",
    "        count_dict[item] = count_dict.get(item, 0) + 1\n",
    "    \n",
    "    for key, value in sorted(count_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save qualifier values to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'GenBankAccession': record_ids,\n",
    "    'Country': countries,\n",
    "    'Host': hosts,\n",
    "    'CollectionDate': collection_years,\n",
    "    'Serotype': serotypes,\n",
    "    'Strain': strains,\n",
    "    'Isolate': isolates,\n",
    "    'IsolationSource': isolation_sources\n",
    "})\n",
    "#df.to_csv('../metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save mapped qualifier values to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'GenBankAccession': record_ids,\n",
    "    'Country': countries_mapped,\n",
    "    'Host': hosts_mapped,\n",
    "    'CollectionDate': collection_years,\n",
    "    'Serotype': serotypes_mapped,\n",
    "    'Strain': strains,\n",
    "    'Isolate': isolates,\n",
    "    'IsolationSource': isolation_sources\n",
    "})\n",
    "#df.to_csv('../metadata_mapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file with sources to remove\n",
    "def read_exclusion_criteria(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        exclusion_criteria = [line.strip() for line in file]\n",
    "    return exclusion_criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function excludes genbank records based on isolation source and reference exclusion criterias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_records(genbank_records, isolation_exclusion_file, reference_exclusion_file, output_file):\n",
    "    isolation_exclusion_criteria = read_exclusion_criteria(isolation_exclusion_file)\n",
    "    reference_exclusion_criteria = read_exclusion_criteria(reference_exclusion_file)\n",
    "\n",
    "    filtered_records = [record for i, record in enumerate(genbank_records)\n",
    "                        if not any(re.search(criteria, isolation_sources[i]) for criteria in isolation_exclusion_criteria)\n",
    "                        and not any(re.search(criteria, references[i]) for criteria in reference_exclusion_criteria)]\n",
    "\n",
    "    with open(output_file, 'w') as genbank_file:\n",
    "        SeqIO.write(filtered_records, genbank_file, 'gb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save filtered records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'BioSample: SAMN42387487, SAMN42387488, SAMN42387489, SAMN42387490, SAMN42387491, SAMN42387492, SAMN42387493, SAMN42387494, SAMN42387495, SAMN42387496, SAMN42387497, SAMN42387498, SAMN42387499, SAMN42387500, SAMN42387501, SAMN42387502, SAMN42387503, SAMN42387504, SAMN42387505, SAMN42387506, SAMN42387507, SAMN42387508, SAMN42387509, SAMN42387510, SAMN42387511, SAMN42387512, SAMN42387513, SAMN42387514, SAMN42387515, SAMN42387516, SAMN42387517, SAMN42387518' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n",
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'Sequence Read Archive: SRR29828681, SRR29828682, SRR29828683, SRR29828684, SRR29828685, SRR29828687, SRR29828688, SRR29828689, SRR29828690, SRR29828691, SRR29828692, SRR29828693, SRR29828694, SRR29828695, SRR29828696, SRR29828698, SRR29828699, SRR29828700, SRR29828701, SRR29828740, SRR29828741, SRR29828742, SRR29828743, SRR29828744, SRR29828745, SRR29828746, SRR29828747, SRR29828749, SRR29828750, SRR29828751, SRR29828752, SRR29828753' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n",
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'BioSample: SAMN42776798, SAMN42776799, SAMN42776800, SAMN42776801, SAMN42776802, SAMN42776803, SAMN42776804, SAMN42776805, SAMN42776806, SAMN42776807, SAMN42776808, SAMN42776809, SAMN42776810, SAMN42776811, SAMN42776812, SAMN42776813, SAMN42776814, SAMN42776815, SAMN42776816, SAMN42776817, SAMN42776818, SAMN42776819, SAMN42776820, SAMN42776821, SAMN42776822, SAMN42776823, SAMN42776824, SAMN42776825, SAMN42776826, SAMN42776827, SAMN42776828, SAMN42776829, SAMN42776830, SAMN42776831, SAMN42776832, SAMN42776833, SAMN42776834, SAMN42776835, SAMN42776836, SAMN42776837, SAMN42776838, SAMN42776839, SAMN42776840, SAMN42776841, SAMN42776842, SAMN42776843, SAMN42776844, SAMN42776845, SAMN42776846, SAMN42776847, SAMN42776848' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n",
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'Sequence Read Archive: SRR29943323, SRR29943334, SRR29943342, SRR29943343, SRR29943344, SRR29943345, SRR29943346, SRR29943347, SRR29943348, SRR29943349, SRR29943350, SRR29943351, SRR29943352, SRR29943353, SRR29943354, SRR29943355, SRR29943356, SRR29943357, SRR29943358, SRR29943359, SRR29943360, SRR29943361, SRR29943362, SRR29943363, SRR29943364, SRR29943365, SRR29943366, SRR29943367, SRR29943368, SRR29943369, SRR29943370, SRR29943371, SRR29943372, SRR29943373, SRR29943374, SRR29943375, SRR29943376, SRR29943377, SRR29943378, SRR29943379, SRR29943380, SRR29943381, SRR29943382, SRR29943383, SRR29943393, SRR29943404, SRR29943422, SRR29943433, SRR29943439, SRR29943440, SRR29943441' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n",
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'BioSample: SAMN42776849, SAMN42776850, SAMN42776851, SAMN42776852, SAMN42776853, SAMN42776854, SAMN42776855, SAMN42776856, SAMN42776857, SAMN42776858, SAMN42776859, SAMN42776860, SAMN42776861, SAMN42776862, SAMN42776863, SAMN42776864, SAMN42776865, SAMN42776866, SAMN42776867, SAMN42776868, SAMN42776869, SAMN42776870, SAMN42776871, SAMN42776872, SAMN42776873, SAMN42776874, SAMN42776875, SAMN42776876, SAMN42776877, SAMN42776878, SAMN42776879, SAMN42776880, SAMN42776881, SAMN42776882, SAMN42776883, SAMN42776884, SAMN42776885, SAMN42776886, SAMN42776887, SAMN42776888, SAMN42776889, SAMN42776890, SAMN42776891, SAMN42776892, SAMN42776893, SAMN42776894, SAMN42776895, SAMN42776896, SAMN42776897, SAMN42776898, SAMN42776899' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n",
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'Sequence Read Archive: SRR29943313, SRR29943314, SRR29943315, SRR29943316, SRR29943317, SRR29943318, SRR29943319, SRR29943320, SRR29943321, SRR29943322, SRR29943324, SRR29943325, SRR29943326, SRR29943327, SRR29943328, SRR29943329, SRR29943330, SRR29943331, SRR29943332, SRR29943333, SRR29943335, SRR29943336, SRR29943337, SRR29943338, SRR29943339, SRR29943340, SRR29943341, SRR29943413, SRR29943414, SRR29943415, SRR29943416, SRR29943417, SRR29943418, SRR29943419, SRR29943420, SRR29943421, SRR29943423, SRR29943424, SRR29943425, SRR29943426, SRR29943427, SRR29943428, SRR29943429, SRR29943430, SRR29943431, SRR29943432, SRR29943434, SRR29943435, SRR29943436, SRR29943437, SRR29943438' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n",
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'BioSample: SAMN42387542, SAMN42387543, SAMN42387544, SAMN42387545, SAMN42387546, SAMN42387547, SAMN42387548, SAMN42387549, SAMN42387550, SAMN42387551, SAMN42387552, SAMN42387553, SAMN42387554' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n",
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'Sequence Read Archive: SRR29828656, SRR29828657, SRR29828658, SRR29828659, SRR29828660, SRR29828661, SRR29828662, SRR29828663, SRR29828664, SRR29828797, SRR29828798, SRR29828799, SRR29828800' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n",
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'BioSample: SAMN42387519, SAMN42387520, SAMN42387521, SAMN42387522, SAMN42387523, SAMN42387524, SAMN42387525, SAMN42387526, SAMN42387527, SAMN42387528, SAMN42387529, SAMN42387530, SAMN42387531, SAMN42387532, SAMN42387533, SAMN42387534, SAMN42387535, SAMN42387536, SAMN42387537, SAMN42387538, SAMN42387539, SAMN42387540, SAMN42387541' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n",
      "d:\\Users\\User\\miniconda3\\envs\\virus\\Lib\\site-packages\\Bio\\SeqIO\\InsdcIO.py:600: BiopythonWarning: Annotation 'Sequence Read Archive: SRR29828739, SRR29828738, SRR29828736, SRR29828735, SRR29828734, SRR29828733, SRR29828732, SRR29828731, SRR29828729, SRR29828680, SRR29828679, SRR29828678, SRR29828676, SRR29828675, SRR29828674, SRR29828673, SRR29828672, SRR29828671, SRR29828670, SRR29828669, SRR29828668, SRR29828667, SRR29828665' too long\n",
      "  warnings.warn(f\"Annotation {text!r} too long\", BiopythonWarning)\n"
     ]
    }
   ],
   "source": [
    "filter_records(genbank_records, '../data/tables_and_maps/isolation_sources_to_remove.txt', '../data/tables_and_maps/references_to_remove.txt', '../filtered_gb_records.gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_hosts = []\n",
    "filtered_collection_dates = []\n",
    "filtered_countries = []\n",
    "filtered_isolation_sources = []\n",
    "filtered_isolates = []\n",
    "filtered_strains = []\n",
    "filtered_serotypes = []\n",
    "filtered_record_ids = []\n",
    "filtered_references = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_filtered_record(record):\n",
    "    features = record.features\n",
    "    source_feature_list = [feature for feature in features if feature.type == 'source']\n",
    "\n",
    "    merged_values = {\n",
    "        'host': [],\n",
    "        'collection_date': [],\n",
    "        'geo_loc_name': [],\n",
    "        'isolation_source': [],\n",
    "        'isolate': [],\n",
    "        'strain': [],\n",
    "        'organism': []\n",
    "    }\n",
    "\n",
    "    for source_feature in source_feature_list:\n",
    "        qual_dict = source_feature.qualifiers\n",
    "\n",
    "        for key in merged_values.keys():\n",
    "            merged_values[key].append(parse_qualifier(qual_dict, key))\n",
    "\n",
    "    filtered_hosts.append(merge_values(merged_values['host']))\n",
    "    filtered_collection_dates.append(merge_values(merged_values['collection_date']))\n",
    "    filtered_countries.append(merge_values(merged_values['geo_loc_name']))\n",
    "    filtered_isolation_sources.append(merge_values(merged_values['isolation_source']))\n",
    "    filtered_isolates.append(merge_values(merged_values['isolate']))\n",
    "    filtered_strains.append(merge_values(merged_values['strain']))\n",
    "    filtered_serotypes.append(merge_values(merged_values['organism']))\n",
    "\n",
    "    for reference in record.annotations[\"references\"]:\n",
    "        filtered_references.append(reference.title)\n",
    "        break\n",
    "  \n",
    "    filtered_record_ids.append(record.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_genbank_records = SeqIO.parse('../filtered_gb_records.gb', 'gb')\n",
    "filtered_genbank_records = list(filtered_genbank_records)\n",
    "for record in filtered_genbank_records:\n",
    "    extract_data_from_filtered_record(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping hosts\n",
    "filtered_hosts_mapped = map_qualifiers(filtered_hosts, '../data/tables_and_maps/host_map.csv')\n",
    "\n",
    "# Mapping countries\n",
    "filtered_countries_mapped = map_qualifiers(filtered_countries, '../data/tables_and_maps/country_map.csv')\n",
    "\n",
    "#Mapping types\n",
    "filtered_serotypes_mapped = map_qualifiers_kobu(filtered_serotypes, '../data/tables_and_maps/kobu_map.csv')\n",
    "\n",
    "# Converting all dates to years\n",
    "filtered_collection_years = ['Unknown' if date == 'Unknown' else (date[-4:] if date[-4:].isdigit() else date[:4]) for date in filtered_collection_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save filtered and mapped qualifier values as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'GenBankAccession': filtered_record_ids,\n",
    "    'Country':          filtered_countries_mapped,\n",
    "    'Host':             filtered_hosts_mapped,\n",
    "    'CollectionDate':   filtered_collection_years,\n",
    "    'Serotype':         filtered_serotypes_mapped,\n",
    "    'Strain':           filtered_strains,\n",
    "    'Isolate':          filtered_isolates,\n",
    "    'IsolationSource':  filtered_isolation_sources\n",
    "})\n",
    "df.to_csv('../metadata_mapped_and_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function extracts CDS sequences and creates a FASTA file with headers in the format >GenbankAC/country/host/year/serotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fasta_from_genbank(genbank_records, hosts, collection_dates, countries, serotypes, record_ids, output_file):\n",
    "    with open(output_file, 'w') as fasta_file:\n",
    "        for i, record in enumerate(genbank_records):  \n",
    "            # Constructing the header\n",
    "            header = f\">{record_ids[i].replace(' ', '-')}/{countries[i].replace(' ', '-')}/{hosts[i].replace(' ', '-')}/{collection_dates[i].replace(' ', '-')}/{serotypes[i].replace(' ', '-')}\"\n",
    "            fasta_file.write(header + '\\n')\n",
    "\n",
    "            cds_list = []\n",
    "            # Getting the coordinates of the coding sequence/sequences\n",
    "            for feature in record.features:\n",
    "                if feature.type == 'CDS':\n",
    "                    # Check if product qualifier is 'polyprotein'\n",
    "                    if 'product' in feature.qualifiers:\n",
    "                        product_value = feature.qualifiers['product'][0]\n",
    "                        pattern = r'(?i)(polyprotein|poylprotein|polyprotein precursor|polypeptide)'\n",
    "                        if re.match(pattern, product_value): \n",
    "                        \n",
    "                            cds_start = feature.location.start\n",
    "                            cds_end = feature.location.end\n",
    "                            \n",
    "                            cds_sequence = record.seq[cds_start:cds_end]\n",
    "                            cds_list.append(str(cds_sequence))\n",
    "                            full_cds = ''.join(cds_list)\n",
    "\n",
    "            # Writing the sequence, moving to a new line every 70 characters\n",
    "            for i in range(0, len(full_cds), 70):\n",
    "                fasta_file.write(str(full_cds[i:i+70]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get FASTA file with host and country mappings and filtered by isolation sources and references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_fasta_from_genbank(genbank_records, hosts, collection_years, countries, serotypes, record_ids, '../CDS.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_fasta_from_genbank(genbank_records, hosts_mapped, collection_years, countries_mapped, serotypes, record_ids, '../CDS_mapped.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_fasta_from_genbank(filtered_genbank_records, filtered_hosts_mapped, filtered_collection_years, filtered_countries_mapped, filtered_serotypes, filtered_record_ids, '../CDS_mapped_and_filtered.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "CHN        227\n",
       "JPN         37\n",
       "AUS         21\n",
       "ESP         21\n",
       "USA         14\n",
       "KOR         14\n",
       "HUN         10\n",
       "VNM         10\n",
       "DEU          9\n",
       "THA          9\n",
       "Unknown      8\n",
       "ITA          7\n",
       "BRA          5\n",
       "PAK          5\n",
       "TZA          4\n",
       "MDG          3\n",
       "TWN          2\n",
       "IND          2\n",
       "GBR          2\n",
       "ARG          2\n",
       "CAN          1\n",
       "MEX          1\n",
       "EGY          1\n",
       "IRL          1\n",
       "NZL          1\n",
       "SLE          1\n",
       "ZMB          1\n",
       "ZAF          1\n",
       "HRV          1\n",
       "NLD          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapped_and_filtered = pd.read_csv('../metadata_mapped_and_filtered.csv')\n",
    "df_mapped_and_filtered['Country'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
